{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c90c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple VAE (Lux) with training loop in user‑requested style\n",
    "# --------------------------------------------------------------------\n",
    "# Implements: `train!(model, ps, st, data; epochs=10)`\n",
    "#   • Initializes `tstate = Training.TrainState(model, ps, st, Adam(...))`\n",
    "#   • Uses `single_train_step!` inside the nested loops\n",
    "#   • Collects `losses` (for visualization) and returns them.\n",
    "# Dataset: MNIST (flattened 28×28), reconstruction target y = x.\n",
    "\n",
    "using Lux, Lux.Training, Random, Optimisers, Zygote, MLDatasets, Functors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80447a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Hyper‑parameters\n",
    "# ------------------------------\n",
    "latent_dim = 10\n",
    "hidden_dim = 128\n",
    "input_dim  = 28 * 28\n",
    "batch_size = 64\n",
    "epochs     = 5\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b42cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: MNIST.traindata() is deprecated, use `MNIST(split=:train)[:]` instead.\n",
      "└ @ MLDatasets /Users/briandepasquale/.julia/packages/MLDatasets/0MkOE/src/datasets/vision/mnist.jl:187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "784×60000 Matrix{Float32}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# MNIST loader that yields (x, y = x) tuples\n",
    "# ------------------------------\n",
    "ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"\n",
    "train_x, _ = MLDatasets.MNIST.traindata()\n",
    "train_x = reshape(Float32.(train_x) ./ 255f0, input_dim, :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d25ac7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_iter (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function batch_iter(X; batch=batch_size, rng=Random.default_rng())\n",
    "    idx = collect(1:size(X, 2))\n",
    "    Random.shuffle!(rng, idx)\n",
    "    for chunk in Iterators.partition(idx, batch)\n",
    "        xb = X[:, chunk]\n",
    "        yield((xb, xb))            # (input, target) pair\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "function encoder(\n",
    "    rng=Random.default_rng();\n",
    "    num_latent_dims::Int,\n",
    "    image_shape::Dims{3},\n",
    "    max_num_filters::Int,\n",
    ")\n",
    "    flattened_dim = prod(image_shape[1:2] .÷ 8) * max_num_filters\n",
    "    return @compact(;\n",
    "        embed=Dense(flattened_dim, flattened_dim; init_bias=zeros32),\n",
    "        proj_mu=Dense(flattened_dim, num_latent_dims; init_bias=zeros32),\n",
    "        proj_log_var=Dense(flattened_dim, num_latent_dims; init_bias=zeros32),\n",
    "        rng\n",
    "    ) do x\n",
    "        y = embed(x)\n",
    "\n",
    "        μ = proj_mu(y)\n",
    "        logσ² = proj_log_var(y)\n",
    "\n",
    "        T = eltype(logσ²)\n",
    "        logσ² = clamp.(logσ², -T(20.0f0), T(10.0f0))\n",
    "        σ = exp.(logσ² .* T(0.5))\n",
    "\n",
    "        # Generate a tensor of random values from a normal distribution\n",
    "        rng = Lux.replicate(rng)\n",
    "        ϵ = randn_like(rng, σ)\n",
    "\n",
    "        # Reparameterization trick to brackpropagate through sampling\n",
    "        z = ϵ .* σ .+ μ\n",
    "\n",
    "        @return z, μ, logσ²\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514e8651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SimpleVAE{@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}((weight = Float32[-0.12327705 -0.11697393 … -0.05656602 0.040849246; 0.015953189 0.08447786 … -0.016243627 -0.024371725; … ; 0.08097171 -0.029226342 … -6.241491f-5 -0.09555681; 0.08673438 -0.005603862 … -0.065215245 -0.043865424], bias = Float32[0.029358562, 0.019185463, -0.01677743, 0.019504147, -0.019974573, 0.0143271815, 0.015715718, 0.004030245, 0.027582126, 0.016351137  …  0.028981255, 0.03434905, 0.028943207, -0.031130774, 0.007312792, 0.026094684, 0.025853554, 0.009912525, -0.02758334, 0.025112638]), (weight = Float32[0.108728476 -0.056329127 … 0.0057340604 0.14007536; 0.14121042 0.14495571 … 0.12086126 0.13093837; … ; -0.047098126 0.017961422 … 0.14909995 0.08167165; 0.06740952 -0.11463427 … -0.099566825 -0.04927186], bias = Float32[-0.014348842, -0.007779212, 0.0300909, 0.0031906008, -0.056306567, -0.07127187, -0.017895384, -0.016890876, 0.07579222, 0.037204772]), (weight = Float32[-0.09150956 0.033682298 … -0.15011606 0.079585716; -0.0019846824 0.09248271 … 0.0048609744 0.13021445; … ; 0.119482994 0.05472806 … -0.08845684 0.14770831; 0.092272155 0.11295679 … 0.09621108 -0.119080305], bias = Float32[0.07852033, -0.015877867, -0.054782327, 0.081865385, -0.06618697, -0.057082236, 0.038032115, -0.067470826, 0.023225484, 0.05878281]), (weight = Float32[-0.31497142 0.34759042 … -0.5467435 0.23188178; -0.8143353 -0.03925295 … 0.660652 -0.3882332; … ; -0.556432 -0.10842579 … 0.9769724 -0.5042178; 0.20850131 1.0175667 … -0.5732511 0.07028518], bias = Float32[-0.27312312, 0.2914099, 0.06662087, -0.025468664, -0.28223887, 0.24194379, 0.12217193, -0.119036764, -0.25831065, 0.22154391  …  -0.20804477, 0.115272686, -0.12644036, -0.07030175, -0.11239684, -0.19321172, 0.031313628, -0.27204448, -0.1202476, -0.1533463]), (weight = Float32[0.06502149 0.051930025 … 0.00026583127 -0.05873818; -0.12499284 -0.02633069 … -0.13223284 0.14327185; … ; -0.06748115 0.12598065 … -0.048517164 0.082860075; 0.10809676 -0.10435571 … -0.03522463 0.039707262], bias = Float32[-0.0035370057, -0.056332015, 0.0630926, -0.016960144, 0.013417312, -0.013109682, -0.07164221, 0.05960025, 0.03615692, 0.07064057  …  0.07882901, 0.066728786, -0.06650668, 0.00264148, -0.08209394, 0.022730859, 0.037149962, -0.030996025, -0.011606579, 0.043388728])), SimpleVAE{@NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}}(NamedTuple(), NamedTuple(), NamedTuple(), NamedTuple(), NamedTuple()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize parameters & state\n",
    "rng = Random.default_rng()\n",
    "ps, st = Lux.setup(rng, vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc18e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Loss helper (MSE + KL)\n",
    "# ------------------------------\n",
    "const mse_loss = MSELoss()\n",
    "\n",
    "function full_loss(model, p, s, x, y, rng)\n",
    "    (x̂, kl), _ = model(x, rng, p, s)\n",
    "    return mse_loss(x̂, y) + kl\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9a728ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(eta=0.03, beta=(0.9, 0.999), epsilon=1.0e-8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = Adam(0.03f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555be7ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching Lux.Training.TrainState(::SimpleVAE{Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, ::SimpleVAE{@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, ::SimpleVAE{@NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}}, ::Adam{Float32, Tuple{Float64, Float64}, Float64})\n\nClosest candidates are:\n  Lux.Training.TrainState(::__T_cache, ::__T_objective_function, ::__T_model, ::__T_parameters, !Matched::__T_states, !Matched::__T_optimizer, !Matched::__T_optimizer_state, !Matched::Int64) where {__T_cache, __T_objective_function, __T_model, __T_parameters, __T_states, __T_optimizer, __T_optimizer_state}\n   @ Lux ~/.julia/packages/ConcreteStructs/7Lv7u/src/ConcreteStructs.jl:142\n  Lux.Training.TrainState(!Matched::AbstractLuxLayer, ::Any, ::Any, ::AbstractRule)\n   @ Lux ~/.julia/packages/Lux/L2VO7/src/helpers/training.jl:65\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Lux.Training.TrainState(::SimpleVAE{Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, ::SimpleVAE{@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, ::SimpleVAE{@NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}}, ::Adam{Float32, Tuple{Float64, Float64}, Float64})\n",
      "\n",
      "Closest candidates are:\n",
      "  Lux.Training.TrainState(::__T_cache, ::__T_objective_function, ::__T_model, ::__T_parameters, !Matched::__T_states, !Matched::__T_optimizer, !Matched::__T_optimizer_state, !Matched::Int64) where {__T_cache, __T_objective_function, __T_model, __T_parameters, __T_states, __T_optimizer, __T_optimizer_state}\n",
      "   @ Lux ~/.julia/packages/ConcreteStructs/7Lv7u/src/ConcreteStructs.jl:142\n",
      "  Lux.Training.TrainState(!Matched::AbstractLuxLayer, ::Any, ::Any, ::AbstractRule)\n",
      "   @ Lux ~/.julia/packages/Lux/L2VO7/src/helpers/training.jl:65\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/GitHub/FNO/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X42sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "tstate = Training.TrainState(vae, ps, st, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b57cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# User‑style training loop\n",
    "# ------------------------------\n",
    "function train!(model, ps, st, data; epochs=10, lr=1e-2, rng=Random.default_rng())\n",
    "    losses = []\n",
    "    tstate = Lux.Training.TrainState((model, ps, st), Optimisers.Adam(lr))\n",
    "    for _ in 1:epochs\n",
    "        for (x, y) in data()\n",
    "            _, loss, _, tstate = Training.single_train_step!(AutoZygote(), loss_closure, (x,y), tstate)\n",
    "            push!(losses, loss)\n",
    "        end\n",
    "    end\n",
    "    return losses, tstate.parameters, tstate.states\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f265d93",
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching Lux.Training.TrainState(::Tuple{SimpleVAE{Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, SimpleVAE{@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, SimpleVAE{@NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}}}, ::Adam{Float64, Tuple{Float64, Float64}, Float64})\n\nClosest candidates are:\n  Lux.Training.TrainState(::__T_cache, ::__T_objective_function, !Matched::__T_model, !Matched::__T_parameters, !Matched::__T_states, !Matched::__T_optimizer, !Matched::__T_optimizer_state, !Matched::Int64) where {__T_cache, __T_objective_function, __T_model, __T_parameters, __T_states, __T_optimizer, __T_optimizer_state}\n   @ Lux ~/.julia/packages/ConcreteStructs/7Lv7u/src/ConcreteStructs.jl:142\n  Lux.Training.TrainState(!Matched::AbstractLuxLayer, ::Any, !Matched::Any, !Matched::AbstractRule)\n   @ Lux ~/.julia/packages/Lux/L2VO7/src/helpers/training.jl:65\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Lux.Training.TrainState(::Tuple{SimpleVAE{Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, SimpleVAE{@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, SimpleVAE{@NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}}}, ::Adam{Float64, Tuple{Float64, Float64}, Float64})\n",
      "\n",
      "Closest candidates are:\n",
      "  Lux.Training.TrainState(::__T_cache, ::__T_objective_function, !Matched::__T_model, !Matched::__T_parameters, !Matched::__T_states, !Matched::__T_optimizer, !Matched::__T_optimizer_state, !Matched::Int64) where {__T_cache, __T_objective_function, __T_model, __T_parameters, __T_states, __T_optimizer, __T_optimizer_state}\n",
      "   @ Lux ~/.julia/packages/ConcreteStructs/7Lv7u/src/ConcreteStructs.jl:142\n",
      "  Lux.Training.TrainState(!Matched::AbstractLuxLayer, ::Any, !Matched::Any, !Matched::AbstractRule)\n",
      "   @ Lux ~/.julia/packages/Lux/L2VO7/src/helpers/training.jl:65\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] train!(model::SimpleVAE{Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(relu), Int64, Int64, Nothing, Nothing, Static.True}, Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, ps::SimpleVAE{@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, @NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, st::SimpleVAE{@NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}, @NamedTuple{}}, data::var\"#12#13\"; epochs::Int64, lr::Float64, rng::TaskLocalRNG)\n",
      "   @ Main ~/Documents/GitHub/FNO/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X35sZmlsZQ==.jl:6\n",
      " [2] top-level scope\n",
      "   @ ~/Documents/GitHub/FNO/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X36sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Run training\n",
    "losses, ps, st = train!(vae, ps, st, data; epochs=epochs, lr=learning_rate, rng=rng)\n",
    "@info \"Done. Final batch loss ≈ $(round(losses[end], sigdigits=5)).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d242f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
